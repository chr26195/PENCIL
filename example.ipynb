{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustration of PENCIL data generation\n",
    "\n",
    "## 1. Generate instances with CoT reasoning steps\n",
    "\n",
    "The following code generates a dataset of 10,200 Quantified Boolean Formula (QBF) instances with exactly `min_vars = max_vars` variables each. Each instance is augmented with reasoning steps (including special tokens) and forms a very long CoT. The data is saved to disk in JSONL format, where each instance contains the formula text, validity label, and size information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000/10200 samples...\n",
      "Generated 2000/10200 samples...\n",
      "Generated 3000/10200 samples...\n",
      "Generated 4000/10200 samples...\n",
      "Generated 5000/10200 samples...\n",
      "Generated 6000/10200 samples...\n",
      "Generated 7000/10200 samples...\n",
      "Generated 8000/10200 samples...\n",
      "Generated 9000/10200 samples...\n",
      "Generated 10000/10200 samples...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataset_qbf import *\n",
    "from pencil_utils import *\n",
    "\n",
    "# Define parameters directly as variables\n",
    "num_samples = 10200\n",
    "data_dir = 'data/qbf'\n",
    "min_vars = 3\n",
    "max_vars = 3\n",
    "\n",
    "# Instantiate QBF generator\n",
    "qbf_gen = QBFGenerator(\n",
    "    min_vars=min_vars,\n",
    "    max_vars=max_vars\n",
    ")\n",
    "\n",
    "# Generate dataset\n",
    "data = qbf_gen.generate_dataset(\n",
    "    num_samples=num_samples,\n",
    "    data_dir=data_dir,\n",
    "    format='pencil',\n",
    "    save=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build tokenizer and data split\n",
    "\n",
    "Create a tokenizer by building a vocabulary from all instances, and then convert the text data into tokenized sequences. The tokenizer simply parses the sequence by blank spaces. The meta information of the tokenizer is stored in `meta.pkl`. \n",
    "\n",
    "Then, the code splits and saves the processed data as binary files for efficient training, with separate files for training, validation, and test sets. It holds out `val_size` and `test_size` samples as validation and test sets. The remaining samples are treated as the training set. For large-scale online training, the training set could be very large, so the training samples are stored in multiple files, each containing `train_size` samples. During training, we load these files sequentially. For example, the following code will create `train0.bin`, `train1.bin`, `val.bin`, and `test.bin`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added special token <|startoftext|> with index 38\n",
      "Added special token <|endofprompt|> with index 17\n",
      "Added special token <|endoftext|> with index 39\n",
      "\n",
      "Token to ID mapping:\n",
      "<UNK>: 0\n",
      "∃: 1\n",
      "3: 2\n",
      "∀: 3\n",
      "2: 4\n",
      "1: 5\n",
      ":: 6\n",
      "#1: 7\n",
      "(: 8\n",
      "∨: 9\n",
      "¬: 10\n",
      "): 11\n",
      "#2: 12\n",
      "#3: 13\n",
      "#4: 14\n",
      "#5: 15\n",
      "#6: 16\n",
      "<|endofprompt|>: 17\n",
      "[CALL]: 18\n",
      "Question:: 19\n",
      "prefix_from: 20\n",
      "Try: 21\n",
      "=: 22\n",
      "False: 23\n",
      "evaluate: 24\n",
      "Check: 25\n",
      "#0: 26\n",
      "True: 27\n",
      "[SEP]: 28\n",
      "Answer:: 29\n",
      "[RETURN]: 30\n",
      "#7: 31\n",
      "Formula: 32\n",
      "#8: 33\n",
      "#9: 34\n",
      "#10: 35\n",
      "#11: 36\n",
      "#12: 37\n",
      "<|startoftext|>: 38\n",
      "<|endoftext|>: 39\n",
      "Removed existing file: train0.bin\n",
      "Removed existing file: train1.bin\n",
      "Processing validation and test sets...\n",
      "Tokenizing validation and test sets...\n",
      "Validation set: 100 sequences, 41,517 tokens\n",
      "Validation max sequence length: 705\n",
      "Test set: 100 sequences, 41,676 tokens\n",
      "Test max sequence length: 730\n",
      "Processing training data in batches...\n",
      "Processing training batch 1...\n",
      "Training batch 1 set: 5,000 sequences, 2,143,909 tokens\n",
      "Training batch 1 max sequence length: 993\n",
      "Processing training batch 2...\n",
      "Training batch 2 set: 5,000 sequences, 2,154,352 tokens\n",
      "Training batch 2 max sequence length: 943\n",
      "Saved 3 training batches to data/qbf/train[0-2].bin\n"
     ]
    }
   ],
   "source": [
    "# Build tokenizer, process dataset, etc.\n",
    "tokenizer = SimpleTokenizer()\n",
    "tokenizer.build_vocab_from_file(data_dir)\n",
    "tokenizer.save_meta_to_file(data_dir)\n",
    "\n",
    "# Train/val splits:\n",
    "train_size = 5000\n",
    "val_size = 100\n",
    "test_size = 100\n",
    "\n",
    "process_dataset(data_dir, \n",
    "                train_size=train_size, \n",
    "                val_size=val_size,\n",
    "                test_size=test_size,\n",
    "                tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check a training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Example Sample:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False [CALL] Question: evaluate 1 = False 2 = False 3 = False Check #0 ( 1 ∨ ¬ 1 ) True Check #1 ( 3 ∨ 1 ∨ ¬ 2 ) True Check #2 ( ¬ 3 ∨ 3 ) True Check #3 ( 2 ) False [SEP] Answer: False [RETURN] [SEP] Answer: False [RETURN] [SEP] Answer: False [RETURN] Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False [CALL] Question: evaluate 1 = False 2 = True 3 = False Check #0 ( 1 ∨ ¬ 1 ) True Check #1 ( 3 ∨ 1 ∨ ¬ 2 ) False [SEP] Answer: False [RETURN] [SEP] Answer: False [RETURN] [SEP] Answer: False [RETURN] [SEP] Answer: False [RETURN] <|endoftext|>\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_bin_file = os.path.join(data_dir, 'train0.bin')\n",
    "with open(train_bin_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "sample = train_data[4]\n",
    "print(f\"An Example Sample:\")\n",
    "print(tokenizer.decode(sample))\n",
    "print(f\"------------------------------------\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training data for PENCIL\n",
    "\n",
    "We next convert a complete reasoning trace into subsequences. The **masked part** represents the input context that the model sees during training, while the **unmasked part** represents the target output that the model needs to predict. During training, we only calculate loss on the unmasked part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Iteration 0 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False [CALL] Question: evaluate 1 = False 2 = False 3 = False Check #0 ( 1 ∨ ¬ 1 ) True Check #1 ( 3 ∨ 1 ∨ ¬ 2 ) True Check #2 ( ¬ 3 ∨ 3 ) True Check #3 ( 2 ) False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|>\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "[CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False [CALL] Question: evaluate 1 = False 2 = False 3 = False Check #0 ( 1 ∨ ¬ 1 ) True Check #1 ( 3 ∨ 1 ∨ ¬ 2 ) True Check #2 ( ¬ 3 ∨ 3 ) True Check #3 ( 2 ) False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Reduced Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False Answer: False\n",
      "--------------------------------------------------------\n",
      "\n",
      "------------------ Iteration 1 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False Answer: False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False Answer: False\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "[SEP] Answer: False [RETURN]\n",
      "\n",
      "Reduced Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False Answer: False\n",
      "--------------------------------------------------------\n",
      "\n",
      "------------------ Iteration 2 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False Answer: False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False [CALL] Question: prefix_from ∀ 3 Try 3 = False Answer: False\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "[SEP] Answer: False [RETURN]\n",
      "\n",
      "Reduced Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False\n",
      "--------------------------------------------------------\n",
      "\n",
      "------------------ Iteration 3 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False [CALL] Question: evaluate 1 = False 2 = True 3 = False Check #0 ( 1 ∨ ¬ 1 ) True Check #1 ( 3 ∨ 1 ∨ ¬ 2 ) False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False [CALL] Question: evaluate 1 = False 2 = True 3 = False Check #0 ( 1 ∨ ¬ 1 ) True Check #1 ( 3 ∨ 1 ∨ ¬ 2 ) False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Reduced Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False Answer: False\n",
      "--------------------------------------------------------\n",
      "\n",
      "------------------ Iteration 4 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False Answer: False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False [CALL] Question: prefix_from ∀ 1 Try 1 = False Answer: False\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "[SEP] Answer: False [RETURN]\n",
      "\n",
      "Reduced Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False Answer: False\n",
      "--------------------------------------------------------\n",
      "\n",
      "------------------ Iteration 5 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False Answer: False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True [CALL] Question: prefix_from ∀ 3 Try 3 = False Answer: False\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "[SEP] Answer: False [RETURN]\n",
      "\n",
      "Reduced Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True Answer: False\n",
      "--------------------------------------------------------\n",
      "\n",
      "------------------ Iteration 6 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True Answer: False [SEP] Answer: False [RETURN]\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> [CALL] Question: prefix_from ∃ 2 Try 2 = False Answer: False Try 2 = True Answer: False\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "[SEP] Answer: False [RETURN]\n",
      "\n",
      "Reduced Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> Answer: False\n",
      "--------------------------------------------------------\n",
      "\n",
      "------------------ Iteration 7 -----------------------\n",
      "Generated Subsequence:\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> Answer: False <|endoftext|>\n",
      "\n",
      "Masked Part (from previous iteration):\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> Answer: False\n",
      "\n",
      "Unmasked Part (i.e. tokens to be generated):\n",
      "<|endoftext|>\n",
      "\n",
      "Reduced Subsequence:\n",
      "Error in encoding\n",
      "<|startoftext|> ∃ 2 ∀ 3 ∀ 1 : #1 ( 1 ∨ ¬ 1 ) #2 ( 3 ∨ 1 ∨ ¬ 2 ) #3 ( ¬ 3 ∨ 3 ) #4 ( 2 ) #5 ( 2 ∨ ¬ 2 ) #6 ( ¬ 3 ∨ 3 ) #7 ( ¬ 1 ∨ 1 ) <|endofprompt|> Answer: False <|endoftext|>\n",
      "--------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subseqs = extract_subseqs(\n",
    "    sample, \n",
    "    tokenizer.word2idx[PENCIL_TOKENS['sep']], \n",
    "    tokenizer.word2idx[PENCIL_TOKENS['call']], \n",
    "    tokenizer.word2idx[PENCIL_TOKENS['return']], \n",
    "    tokenizer.word2idx['<|endofprompt|>']\n",
    ")\n",
    "\n",
    "for i, subseq in enumerate(subseqs):\n",
    "    print(f\"------------------ Iteration {i} -----------------------\") \n",
    "    print(f\"Generated Subsequence:\")\n",
    "    print(tokenizer.decode(subseq[\"ids\"]))\n",
    "    print()\n",
    "    print(f\"Masked Part (from previous iteration):\")\n",
    "    print(tokenizer.decode(subseq[\"ids\"][:subseq[\"mask_idx\"]+1]))\n",
    "    print()\n",
    "    print(f\"Unmasked Part (i.e. tokens to be generated):\")\n",
    "    print(tokenizer.decode(subseq[\"ids\"][subseq[\"mask_idx\"]+1:]))\n",
    "    print()\n",
    "    print(f\"Reduced Subsequence:\")\n",
    "    reduced_encoding = reduce_encoding(\n",
    "        subseq[\"ids\"],\n",
    "        tokenizer.word2idx[PENCIL_TOKENS['sep']], \n",
    "        tokenizer.word2idx[PENCIL_TOKENS['call']], \n",
    "        tokenizer.word2idx[PENCIL_TOKENS['return']]\n",
    "    )\n",
    "    print(tokenizer.decode(reduced_encoding))\n",
    "    print(f\"--------------------------------------------------------\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this procedure to the whole training set, which will create `pencil0.bin` and `pencil1.bin` in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to pencil format...\n",
      "\n",
      "Processing batch 0...\n",
      "Batch 0 stats:\n",
      "Samples: 5000 → 55286\n",
      "Tokens: 2143909 → 6737441\n",
      "\n",
      "Processing batch 1...\n",
      "Batch 1 stats:\n",
      "Samples: 5000 → 55562\n",
      "Tokens: 2154352 → 6784625\n",
      "\n",
      "Overall statistics:\n",
      "Total samples: 10000 → 110848\n",
      "Total tokens: 4298261 → 13522066\n",
      "Max length: 993 → 293\n",
      "Average length: 429.8 → 122.0\n",
      "Average reductions per sample: 11.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "110848"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_pencil_data(data_dir, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
